# User testing
## Assumption testing
### First iteration survey
**Goals of the first survey :**
To assess the ease of use, and general effectiveness of the first design of our application. 
The layout, general design, and the kind of data shown on the app had to be reviewed by the maximum number of people 
in order to appeal to the public.

**Targets :**
The target users are people who want to do some sport activity outside and socialize at the same time. 
They are not necessarily runners but want to exercise and share some time with others. 
The other target is the casual runners, those who run from time to time. 
The targets are both women and men, especially the young or middle age.

**Participants :**
To recruit the participants, a survey was done on Google form, and sent to two different University of London channels on Slack. 
The survey was also sent through different means (acquaintances, LinkedIn). A message was sent alongside the survey, explaining what it was about. 
Even though a goal was not set as regards to the number of participants, we aimed at gathering as many responses as possible 
in order to properly analyze the data.

**Tasks :**
We drew up a set of 14 questions on Google Forms aimed at the assessment of our application prototype.

**Results :**
38 answers had been collected. The results gave us useful information about the kind of layout and tracking data 
that should be made available on the application.

**Improvements :**
The first design was improved based on the feedback received. 
For example: the clickable icons at the bottom of the screen design are selected instead of the drop-down menu.

### Second iteration survey
The second iteration was drawn up from the feedback received from the first survey. 
This second survey took into account the selected designs from the first survey.

**Goal :**
To select the colors and design of buttons/icons to make the application appealing to the audience.

**Target Audience :**
The target audience remains the same as in the first survey.

**Participants :**
The mode of recruitment remains the same as the first survey. 
A Google form survey is sent on Slack and other Internet platforms.

**Tasks :**
6 questions only were drawn up for the second survey on Google Forms. 
The questions were more focused on the colors, the styles of the icons, the map, and the progress bar.

**Results :** 23 answers had been collected. 

**Improvements :**
The feedback allowed to choose the colors and icons for our application.

## System Usability Scale
**Methodology :**
The SUS methodology consists of 10 questions, each rated on a 5-point Likert scale ranging from "Strongly Disagree" to "Strongly Agree". 
The questions are formulated to assess different aspects of the user experience, such as ease of use, learnability, efficiency, and overall satisfaction.

**Participants :**
Besides the students who participated from the Slack channel, family members and friends were involved in giving their feedback about the application.

**Tasks :**
The system usability scale survey was done on Google Forms. A link to the prototype was given along with the survey. 
The prototype was made on the UX tool Axure.

**Results :**
From the feedback of 14 participants, the mean SUS score is 66.79%, which is below the average of 68%. It suggests that some aspects of the app were well-received and easy to use, but there are also areas where improvements could be made to improve the user experience.

**Improvements :**
We made some conclusions from the SUS results. Some wording or layout may have been confusing for the users.
Some adjustments were made. For example, “Select a line” was changed to “Click a line” in the Routes page.

## Observations
It was hard to identify what needed improvement from the SUS survey alone, with no open-ended questions.
For more detailed insights, we gathered additional user feedback directly from three friends and family members to better identify any underlying problems.
Their feedback was recorded on video when they used the app.

There were some confusions about what is clickable or not, particularly on the routes page or on how to create a session.
Users had to spend some time to find out that they had to click on the dots for the starting and ending station.
One user suggested that in the list of running sessions, there is not a “Book” button directly.
We have indeed to click on “Details” in order to book.

These concerns will need to be addressed in order to improve the experience with our application.